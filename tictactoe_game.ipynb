{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tictactoe game.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMg+dHOdDQS+8BcIzGhMWm2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soma2000-lang/Tic-tac-toe-game/blob/master/tictactoe_game.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybnkJ08Ldu_u"
      },
      "source": [
        "import numpy as np\r\n",
        "import pickle\r\n",
        "\r\n",
        "BOARD_ROWS = 3\r\n",
        "BOARD_COLS = 3\r\n",
        "BOARD_SIZE = BOARD_ROWS * BOARD_COLS\r\n",
        "\r\n",
        "\r\n",
        "class State:\r\n",
        "    def __init__(self):\r\n",
        "        # the board is represented by an n * n array,\r\n",
        "        # 1 represents a chessman of the player who moves first,\r\n",
        "        # -1 represents a chessman of another player\r\n",
        "        # 0 represents an empty position\r\n",
        "        self.data = np.zeros((BOARD_ROWS, BOARD_COLS))\r\n",
        "        self.winner = None\r\n",
        "        self.hash_val = None\r\n",
        "        self.end = None\r\n",
        "\r\n",
        "    # compute the hash value for one state, it's unique\r\n",
        "    def hash(self):\r\n",
        "        if self.hash_val is None:\r\n",
        "            self.hash_val = 0\r\n",
        "            for i in np.nditer(self.data):\r\n",
        "                self.hash_val = self.hash_val * 3 + i + 1\r\n",
        "        return self.hash_val\r\n",
        "\r\n",
        "    # check whether a player has won the game, or it's a tie\r\n",
        "    def is_end(self):\r\n",
        "        if self.end is not None:\r\n",
        "            return self.end\r\n",
        "        results = []\r\n",
        "        # check row\r\n",
        "        for i in range(BOARD_ROWS):\r\n",
        "            results.append(np.sum(self.data[i, :]))\r\n",
        "        # check columns\r\n",
        "        for i in range(BOARD_COLS):\r\n",
        "            results.append(np.sum(self.data[:, i]))\r\n",
        "\r\n",
        "        # check diagonals\r\n",
        "        trace = 0\r\n",
        "        reverse_trace = 0\r\n",
        "        for i in range(BOARD_ROWS):\r\n",
        "            trace += self.data[i, i]\r\n",
        "            reverse_trace += self.data[i, BOARD_ROWS - 1 - i]\r\n",
        "        results.append(trace)\r\n",
        "        results.append(reverse_trace)\r\n",
        "\r\n",
        "        for result in results:\r\n",
        "            if result == 3:\r\n",
        "                self.winner = 1\r\n",
        "                self.end = True\r\n",
        "                return self.end\r\n",
        "            if result == -3:\r\n",
        "                self.winner = -1\r\n",
        "                self.end = True\r\n",
        "                return self.end\r\n",
        "\r\n",
        "        # whether it's a tie\r\n",
        "        sum_values = np.sum(np.abs(self.data))\r\n",
        "        if sum_values == BOARD_SIZE:\r\n",
        "            self.winner = 0\r\n",
        "            self.end = True\r\n",
        "            return self.end\r\n",
        "\r\n",
        "        # game is still going on\r\n",
        "        self.end = False\r\n",
        "        return self.end\r\n",
        "\r\n",
        "    # @symbol: 1 or -1\r\n",
        "    # put chessman symbol in position (i, j)\r\n",
        "    def next_state(self, i, j, symbol):\r\n",
        "        new_state = State()\r\n",
        "        new_state.data = np.copy(self.data)\r\n",
        "        new_state.data[i, j] = symbol\r\n",
        "        return new_state\r\n",
        "\r\n",
        "    # print the board\r\n",
        "    def print_state(self):\r\n",
        "        for i in range(BOARD_ROWS):\r\n",
        "            print('-------------')\r\n",
        "            out = '| '\r\n",
        "            for j in range(BOARD_COLS):\r\n",
        "                if self.data[i, j] == 1:\r\n",
        "                    token = '*'\r\n",
        "                elif self.data[i, j] == -1:\r\n",
        "                    token = 'x'\r\n",
        "                else:\r\n",
        "                    token = '0'\r\n",
        "                out += token + ' | '\r\n",
        "            print(out)\r\n",
        "        print('-------------')\r\n",
        "\r\n",
        "\r\n",
        "def get_all_states_impl(current_state, current_symbol, all_states):\r\n",
        "    for i in range(BOARD_ROWS):\r\n",
        "        for j in range(BOARD_COLS):\r\n",
        "            if current_state.data[i][j] == 0:\r\n",
        "                new_state = current_state.next_state(i, j, current_symbol)\r\n",
        "                new_hash = new_state.hash()\r\n",
        "                if new_hash not in all_states:\r\n",
        "                    is_end = new_state.is_end()\r\n",
        "                    all_states[new_hash] = (new_state, is_end)\r\n",
        "                    if not is_end:\r\n",
        "                        get_all_states_impl(new_state, -current_symbol, all_states)\r\n",
        "\r\n",
        "\r\n",
        "def get_all_states():\r\n",
        "    current_symbol = 1\r\n",
        "    current_state = State()\r\n",
        "    all_states = dict()\r\n",
        "    all_states[current_state.hash()] = (current_state, current_state.is_end())\r\n",
        "    get_all_states_impl(current_state, current_symbol, all_states)\r\n",
        "    return all_states\r\n",
        "\r\n",
        "\r\n",
        "# all possible board configurations\r\n",
        "all_states = get_all_states()\r\n",
        "\r\n",
        "\r\n",
        "class Judger:\r\n",
        "    # @player1: the player who will move first, its chessman will be 1\r\n",
        "    # @player2: another player with a chessman -1\r\n",
        "    def __init__(self, player1, player2):\r\n",
        "        self.p1 = player1\r\n",
        "        self.p2 = player2\r\n",
        "        self.current_player = None\r\n",
        "        self.p1_symbol = 1\r\n",
        "        self.p2_symbol = -1\r\n",
        "        self.p1.set_symbol(self.p1_symbol)\r\n",
        "        self.p2.set_symbol(self.p2_symbol)\r\n",
        "        self.current_state = State()\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.p1.reset()\r\n",
        "        self.p2.reset()\r\n",
        "\r\n",
        "    def alternate(self):\r\n",
        "        while True:\r\n",
        "            yield self.p1\r\n",
        "            yield self.p2\r\n",
        "\r\n",
        "    # @print_state: if True, print each board during the game\r\n",
        "    def play(self, print_state=False):\r\n",
        "        alternator = self.alternate()\r\n",
        "        self.reset()\r\n",
        "        current_state = State()\r\n",
        "        self.p1.set_state(current_state)\r\n",
        "        self.p2.set_state(current_state)\r\n",
        "        if print_state:\r\n",
        "            current_state.print_state()\r\n",
        "        while True:\r\n",
        "            player = next(alternator)\r\n",
        "            i, j, symbol = player.act()\r\n",
        "            next_state_hash = current_state.next_state(i, j, symbol).hash()\r\n",
        "            current_state, is_end = all_states[next_state_hash]\r\n",
        "            self.p1.set_state(current_state)\r\n",
        "            self.p2.set_state(current_state)\r\n",
        "            if print_state:\r\n",
        "                current_state.print_state()\r\n",
        "            if is_end:\r\n",
        "                return current_state.winner\r\n",
        "\r\n",
        "\r\n",
        "# AI player\r\n",
        "class Player:\r\n",
        "    # @step_size: the step size to update estimations\r\n",
        "    # @epsilon: the probability to explore\r\n",
        "    def __init__(self, step_size=0.1, epsilon=0.1):\r\n",
        "        self.estimations = dict()\r\n",
        "        self.step_size = step_size\r\n",
        "        self.epsilon = epsilon\r\n",
        "        self.states = []\r\n",
        "        self.greedy = []\r\n",
        "        self.symbol = 0\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.states = []\r\n",
        "        self.greedy = []\r\n",
        "\r\n",
        "    def set_state(self, state):\r\n",
        "        self.states.append(state)\r\n",
        "        self.greedy.append(True)\r\n",
        "\r\n",
        "    def set_symbol(self, symbol):\r\n",
        "        self.symbol = symbol\r\n",
        "        for hash_val in all_states:\r\n",
        "            state, is_end = all_states[hash_val]\r\n",
        "            if is_end:\r\n",
        "                if state.winner == self.symbol:\r\n",
        "                    self.estimations[hash_val] = 1.0\r\n",
        "                elif state.winner == 0:\r\n",
        "                    # we need to distinguish between a tie and a lose\r\n",
        "                    self.estimations[hash_val] = 0.5\r\n",
        "                else:\r\n",
        "                    self.estimations[hash_val] = 0\r\n",
        "            else:\r\n",
        "                self.estimations[hash_val] = 0.5\r\n",
        "\r\n",
        "    # update value estimation\r\n",
        "    def backup(self):\r\n",
        "        states = [state.hash() for state in self.states]\r\n",
        "\r\n",
        "        for i in reversed(range(len(states) - 1)):\r\n",
        "            state = states[i]\r\n",
        "            td_error = self.greedy[i] * (\r\n",
        "                self.estimations[states[i + 1]] - self.estimations[state]\r\n",
        "            )\r\n",
        "            self.estimations[state] += self.step_size * td_error\r\n",
        "\r\n",
        "    # choose an action based on the state\r\n",
        "    def act(self):\r\n",
        "        state = self.states[-1]\r\n",
        "        next_states = []\r\n",
        "        next_positions = []\r\n",
        "        for i in range(BOARD_ROWS):\r\n",
        "            for j in range(BOARD_COLS):\r\n",
        "                if state.data[i, j] == 0:\r\n",
        "                    next_positions.append([i, j])\r\n",
        "                    next_states.append(state.next_state(\r\n",
        "                        i, j, self.symbol).hash())\r\n",
        "\r\n",
        "        if np.random.rand() < self.epsilon:\r\n",
        "            action = next_positions[np.random.randint(len(next_positions))]\r\n",
        "            action.append(self.symbol)\r\n",
        "            self.greedy[-1] = False\r\n",
        "            return action\r\n",
        "\r\n",
        "        values = []\r\n",
        "        for hash_val, pos in zip(next_states, next_positions):\r\n",
        "            values.append((self.estimations[hash_val], pos))\r\n",
        "        # to select one of the actions of equal value at random due to Python's sort is stable\r\n",
        "        np.random.shuffle(values)\r\n",
        "        values.sort(key=lambda x: x[0], reverse=True)\r\n",
        "        action = values[0][1]\r\n",
        "        action.append(self.symbol)\r\n",
        "        return action\r\n",
        "\r\n",
        "    def save_policy(self):\r\n",
        "        with open('policy_%s.bin' % ('first' if self.symbol == 1 else 'second'), 'wb') as f:\r\n",
        "            pickle.dump(self.estimations, f)\r\n",
        "\r\n",
        "    def load_policy(self):\r\n",
        "        with open('policy_%s.bin' % ('first' if self.symbol == 1 else 'second'), 'rb') as f:\r\n",
        "            self.estimations = pickle.load(f)\r\n",
        "\r\n",
        "\r\n",
        "# human interface\r\n",
        "# input a number to put a chessman\r\n",
        "# | q | w | e |\r\n",
        "# | a | s | d |\r\n",
        "# | z | x | c |\r\n",
        "class HumanPlayer:\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        self.symbol = None\r\n",
        "        self.keys = ['q', 'w', 'e', 'a', 's', 'd', 'z', 'x', 'c']\r\n",
        "        self.state = None\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def set_state(self, state):\r\n",
        "        self.state = state\r\n",
        "\r\n",
        "    def set_symbol(self, symbol):\r\n",
        "        self.symbol = symbol\r\n",
        "\r\n",
        "    def act(self):\r\n",
        "        self.state.print_state()\r\n",
        "        key = input(\"Input your position:\")\r\n",
        "        data = self.keys.index(key)\r\n",
        "        i = data // BOARD_COLS\r\n",
        "        j = data % BOARD_COLS\r\n",
        "        return i, j, self.symbol\r\n",
        "\r\n",
        "\r\n",
        "def train(epochs, print_every_n=500):\r\n",
        "    player1 = Player(epsilon=0.01)\r\n",
        "    player2 = Player(epsilon=0.01)\r\n",
        "    judger = Judger(player1, player2)\r\n",
        "    player1_win = 0.0\r\n",
        "    player2_win = 0.0\r\n",
        "    for i in range(1, epochs + 1):\r\n",
        "        winner = judger.play(print_state=False)\r\n",
        "        if winner == 1:\r\n",
        "            player1_win += 1\r\n",
        "        if winner == -1:\r\n",
        "            player2_win += 1\r\n",
        "        if i % print_every_n == 0:\r\n",
        "            print('Epoch %d, player 1 winrate: %.02f, player 2 winrate: %.02f' % (i, player1_win / i, player2_win / i))\r\n",
        "        player1.backup()\r\n",
        "        player2.backup()\r\n",
        "        judger.reset()\r\n",
        "    player1.save_policy()\r\n",
        "    player2.save_policy()\r\n",
        "\r\n",
        "\r\n",
        "def compete(turns):\r\n",
        "    player1 = Player(epsilon=0)\r\n",
        "    player2 = Player(epsilon=0)\r\n",
        "    judger = Judger(player1, player2)\r\n",
        "    player1.load_policy()\r\n",
        "    player2.load_policy()\r\n",
        "    player1_win = 0.0\r\n",
        "    player2_win = 0.0\r\n",
        "    for _ in range(turns):\r\n",
        "        winner = judger.play()\r\n",
        "        if winner == 1:\r\n",
        "            player1_win += 1\r\n",
        "        if winner == -1:\r\n",
        "            player2_win += 1\r\n",
        "        judger.reset()\r\n",
        "    print('%d turns, player 1 win %.02f, player 2 win %.02f' % (turns, player1_win / turns, player2_win / turns))\r\n",
        "\r\n",
        "\r\n",
        "# The game is a zero sum game. If both players are playing with an optimal strategy, every game will end in a tie.\r\n",
        "# So we test whether the AI can guarantee at least a tie if it goes second.\r\n",
        "def play():\r\n",
        "    while True:\r\n",
        "        player1 = HumanPlayer()\r\n",
        "        player2 = Player(epsilon=0)\r\n",
        "        judger = Judger(player1, player2)\r\n",
        "        player2.load_policy()\r\n",
        "        winner = judger.play()\r\n",
        "        if winner == player2.symbol:\r\n",
        "            print(\"You lose!\")\r\n",
        "        elif winner == player1.symbol:\r\n",
        "            print(\"You win!\")\r\n",
        "        else:\r\n",
        "            print(\"It is a tie!\")\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    train(int(1e5))\r\n",
        "    compete(int(1e3))\r\n",
        "    play()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}